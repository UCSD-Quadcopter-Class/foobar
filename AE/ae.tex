

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove above part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \clearpage 
\appendix
\section{Artifact Appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Abstract}

This appendix provides the necessary information for obtaining the source code,
building, and running performance and functionality tests of Corundum. 
We describe the hardware and software requirements to run the
experiments and reproduce the results as they appear in \refsec{sec:results}.

\subsection{Artifact check-list (meta-information)}

{\small
\begin{itemize}
  \item {\bf Program: } Corundum library and its unit tests, Rust, Cargo, PMDK v1.8, Atlas, Mnemosyne, and go-mem. Input files for the experiments are included (74~MB).
  \item {\bf Compilation: } \This{}: Rust 1.52.0-nightly (publicly available); PMDK, Atlas, Mnemosyne: GNU C++11, CMake $>=$ 3.3; go-pmem: Go lang.
  \item {\bf Data set: } Data set is included (Will be downloaded automatically)
  \item {\bf Run-time environment: } Linux (tested in Ubuntu 20.04, Fedora 27, and NixOS). The NVMM should be mounted in \verb+/mnt/pmem0+ using a DAX-enabled file system (e.g. EXT4-DAX). We also provide a docker image containing Ubuntu 20.04 LTE with pre-installed dependencies.
  \item {\bf Hardware: } A machine with a 16-core Intel processor with 32 GB or larger NVMM (e.g. Optane DC). The docker does not require NVMM and uses DRAM to emulate NVMM. The ISA should provide \verb+CL_FLUSHOPT+ since we customized Atlas to use it instead of \verb+CL_FLUSH+. Other libraries are adaptable to the system configuration.
  \item {\bf Metrics: } Execution time
  \item {\bf Output: } Numerical results stored in \verb+perf.csv+, \verb+scale.csv+, and \verb+micro.csv+ for performance, scalability, and micro-benchmarks, respectively. Expected results are also included in the text.
  \item {\bf Experiments: } A script is provided to run the experiments and generate results. Although the results may vary depending on the build and the environment, there should not be a big difference.
  \item {\bf How much disk space required (approximately)?: } 32~GB
  \item {\bf How much time is needed to prepare workflow\linebreak(approximately)?: } 30 minutes.
  \item {\bf How much time is needed to complete experiments (approximately)?: } $\leq$ 1 hour.
  \item {\bf Publicly available?: } Code, unit-tests, documentation, examples, and evaluation scripts are publicly available.
  \item {\bf Code licenses (if publicly available)?: } Apache v2.0
  \item {\bf Archived (provide DOI)?: } \href{https://zenodo.org/record/4539743}{DOI: 10.5281/zenodo.4539743}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Description}

\subsubsection{How to access}

The artifacts are publicly available
through Zenodo archival repository and GitHub. You can access the code by using its \href{https://zenodo.org/record/4321062}{DOI} or cloning the GitHub repository at \href{https://github.com/NVSL/Corundum/}{https://github.com/NVSL/Corundum/}.
We also prepared a Docker image available at DockerHub (\href{https://hub.docker.com/r/mhz88/corundum}{mhz88/corundum:latest}).

\subsubsection{Hardware dependencies}

We recommend running the experiments on a machine with a physical persistent memory such as Intel Optane DC with at least 32~GB available space.

Also, the scalability test requires a 16-core processor to measure the execution time while running threads in parallel.

\subsubsection{Software dependencies}

\begin{itemize}
  \item To install \This{} without running the evaluations, installing Rust compiler with Cargo tool (1.52.0-nightly) would suffice.
  \item To measure performance, we use \verb+perf+ (>=4.9.215), a linux (kernel>=3.10.0) builtin monitoring tool for analyzing programs (automated installation is included in `\verb+eval/ubuntu-deps.sh+').
  \item If you wish to use Docker, please install Docker and use the prepared docker image with pre-installed dependencies. Otherwise, please run os specific setup scripts (e.g `\verb+eval/ubuntu-deps.sh+' on Ubuntu latest version).
  \item `\verb+eval/build.sh+' compiles and installs other libraries and workloads for comparison. It internally calls `\verb+build.sh+' scripts for each individual library (can be found in `\verb+eval/pmdk+', `\verb+eval/atlas+',\linebreak`\verb+eval/mnemosyne+', and `\verb+eval/go+').
\end{itemize}

\subsection{Installation}

The docker image already has the dependencies pre-installed. If you wish to run it on a real system, please follow the steps in the rest of this section.

\subsubsection{Installing Rust}

If you prefer installing Rust manually rather than running `\verb+ubuntu-deps.sh+', please follow through these steps.
On a Unix-like OS machine, the following commands
install Rust compiler, Cargo, and \verb+rustup+. 

\begin{verbatim}
$ curl --proto '=https' --tlsv1.2 \
     -sSf https://sh.rustup.rs | sh
$ source $HOME/.cargo/env
$ rustup default nightly
\end{verbatim}

% If tou are using
% another OS, please refer to Rust's official website
% for the instructions at
% \begin{center}
%   \href{https://www.rust-lang.org/tools/install}{https://www.rust-lang.org/tools/install}
% \end{center}

\subsubsection{Building Corundum}

Corundum is publicly available in GitHub. Please use
the following commands to clone and compile it.

\begin{verbatim}
$ git clone https://github.com/NVSL/Corundum.git
$ cd Corundum
$ cargo build --release --examples
\end{verbatim}

\subsubsection{Verifying the compilation}

Optionally you can run the tests to verify it.
Since tests may share pool files, we run them sequentially.

\begin{verbatim}
$ cargo test --tests -- --test-threads=1 
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment workflow}

Running the experiments is automated though the following set of commands:

\begin{verbatim}
$ sudo sysctl -w kernel.perf_event_paranoid=-1
$ git clone https://github.com/NVSL/Corundum.git
$ cd Corundum/eval
$ ./ubuntu-deps.sh  # Install dependencies
$ ./build.sh        # Build the libraries and workloads
$ ./run.sh -o       # Run the tests with CLFLUSHOPT
$ ./results.sh      # Display the results
\end{verbatim}

The \verb+eval/ubuntu-deps.sh+ downloads necessary dependencies, and \verb+eval/build.sh+ compiles the benchmark applications.
\verb+eval/run.sh+ executes benchmarks and collects the results, and generates three files:

\begin{itemize}
  \item \verb+perf.csv+: Compares Corundum with other libraries (\reffig{fig:perf})
  \item \verb+scale.csv+: Evaluates multi-threading scalability (\reffig{fig:scal})
  \item \verb+micro.csv+: Lists average latency for basic operations (\reftab{tab:microbench})
\end{itemize}

\noindent Finally, \verb+eval/results.sh+ displays the results on screen.


\subsection{Evaluation on Docker}

We also prepared a docker image with pre-installed dependencies, PMDK (libpmemobj and libpmemobj-cpp), Atlas, Mnemosyne, go-pmem, Corundum, and the input datasets. To emulate PM using DRAM, we bind \verb+/dev/shm+ to a directory inside the docker (i.e. `\verb+-v /dev/shm:/mnt/pmem0+'). To use real PM, you may mount it to a folder as explained in \refsec{sec:custom}, and then replace \verb+/dev/shm+ in the command line arguments with the mount point directory (e.g. \verb+-v /mnt/pmem0:/mnt/pmem0+). We also need to enable \verb+perf_event_open+ system calls. Please run the following commands on the host machine to give permission to, download, and run the docker image.


\begin{verbatim}
$ sudo sysctl -w kernel.perf_event_paranoid=-1
$ wget https://raw.githubusercontent.com/NVSL/
Corundum/main/eval/docker-default.json
$ docker run --security-opt \
    seccomp=./docker-default.json \
    -v /dev/shm:/mnt/pmem0 \
    -it mhz88/corundum:latest bin/bash
\end{verbatim}
% docker run --security-opt \
%     seccomp=./docker-default.json \
%     --mount type=tmpfs,destination=/mnt/pmem0 \
%     -it mhz88/corundum:latest bin/bash

\noindent
Inside the docker, use the following commands to run the experiments:

\begin{verbatim}
$ cd ~/Corundum/eval
$ ./run.sh && ./results.sh
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation and expected results}

We discuss performance evaluation in terms of execution time compared with equivalent implementations in PMDK, Atlas, Mnemosyne, go-pmem, and execution time using multiple threads to show its scalability. 

\subsubsection{Performance}

To compare Corundum's performance with other libraries, we use three applications: BST, VKStore, and B+Tree. The provided script runs these applications automatically with random inputs. The results are stored in \verb+perf.csv+ and should look like \reftab{tbl:perf}. Please modify other library installations as needed since we do not guarantee them.

\begin{table}
  \center
  \small
  \setlength\tabcolsep{1.5pt}
  \caption{Expected output for performance comparison between Corundum and a selection of other libraries (\csym{perf.csv}). \reffig{fig:perf} graphically represetns this data.}
  \label{tbl:perf}
  \begin{tabular}{|r|c|c|c|c|c|c|c|c|} \hline
    \multicolumn{9}{|c|}{Execution Time (s)}	\\ \hline						
    & \multicolumn{2}{|c|}{BST}	& \multicolumn{2}{|c|}{KVStore}&\multicolumn{4}{|c|}{B+Tree}	     \\\hline	
    & INS&CHK&PUT&GET&INS&CHK&REM&RAND           \\\hline
    PMDK     &3.9&5.3&2.1&1.1&4.7&1.0&3.9&3.4    \\\hline
    Atlas    &2.5&2.3&2.0&1.5&20.6&0.4&13.0&11.9 \\\hline
    Mnemosyne&14.0&1.8&2.5&1.5&14.9&1.2&6.0&8.5  \\\hline
    go-pmem  &4.6&3.2&1.1&1.0&4.6&2.5&3.4&3.2    \\\hline
    Corundum &3.3&3.1&0.8&0.4&4.8&0.5&4.6&3.1    \\\hline
  \end{tabular}
\end{table}


\subsubsection{Scalability}
To verify that Corundum provides scalability with respect to the number of threads, we implemented a MapReduce application called \verb+grep+ (referred as \verb+wordcount+ in the text) which counts the frequency of every word in a list of text documents. The producer threads fill up a shared stack, and the consumer threads pop a segment from the stack and count the number of appearance of every words in the segment locally. We do not collect the local records because it adds a fixed amount of execution time to sequentially fetch data from threads. This is to better evaluate the scalability of the library. \reftab{tbl:scale} (\reffig{fig:scal}) shows the expected speedup in execution time for various number of producer (p) and consumer (c) threads. We use Large Canterbury Corpus (http://www.data-compression.info/Corpora/CanterburyCorpus/) dataset as the input files (included in the archive).

\begin{table}[!ht]
  \caption{Expected output for Scalability (scale.csv) using emulated PM. \reffig{fig:scal} graphically represents this data.}
  \label{tbl:scale}
  \begin{tabular}{|c|c|c|c|c|c|c|c|} \hline
    seq&1:1&1:2&1:3&1:4&1:5&1:6&1:7\\\hline
    1.0&1.4&2.9&4.1&5.2&6.2&7.4&8.7\\\hline\hline
    1:8&1:9&1:10&1:11&1:12&1:13&1:14&1:15\\\hline
    9.5&11.1&12.3&13.2&14.2&15.0&15.7&15.9\\\hline
  \end{tabular}
\end{table}


\subsubsection{Microbenchmarks}
The run script also reproduces \reftab{tab:microbench}. To measure the latency of each individual operation, we use a Rust provided measurement tool called \csym{Instant} and \csym{Duration}. On Linux, it internally uses \cfunc{clock\_gettime} system call. Since this tool is not zero cost, for operations with low latency such as \csym{Deref}, we measure running a batch of 50k of them and then calculate the average number. For these operations, we cannot report standard deviation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experiment customization}
\label{sec:custom}

Corundum requires a DAX-enabled file system. We recommend EXT4-DAX. If you run the experiments on a real machine, use the following commands to format and mount the drive (assuming the device name is \verb+/dev/pmem0+):

\begin{verbatim}
$ sudo mkdir /mnt/pmem0
$ sudo mkfs.ext4 /dev/pmem0
$ sudo mount -t ext4 -o dax /dev/pmem0 /mnt/pmem0
$ sudo chmod -R 777 /mnt/pmem0
\end{verbatim}

If there is no pmem device available, you may emulate it using DRAM though the following instructions:

\begin{verbatim}
$ sudo mkdir /mnt/pmem0
$ sudo mount -t tmpfs /dev/pmem0 /mnt/pmem0
\end{verbatim}

Many of the latency components are originated in Hardware, such as using \verb+CL_FLUSHOPT+ instead of \verb+CL_FLUSH+ when available. Corundum does not automatically detect these capabilities. However, it comes with some builtin features. In `\verb+Cargo.toml+', under the `features' section, update \verb+default=[]+ or use `\verb+--feature="..."+' argument as required. For example, if the system supports \verb+CLWB+ instructions, you may force Corundum to use that by changing the default features to this:

\begin{center}
  \verb+default = ["use_clwb"]+
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Methodology}

Submission, reviewing and badging methodology:

\begin{itemize}
  \item \url{https://www.acm.org/publications/policies/artifact-review-badging}
  \item \url{http://cTuning.org/ae/submission-20201122.html}
  \item \url{http://cTuning.org/ae/reviewing-20201122.html}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% When adding this appendix to your paper, 
% please remove below part
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

